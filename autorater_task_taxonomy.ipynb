{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b059e566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "def parent_annotate(folder):\n",
    "    #the full folder has a list of folders with a name\n",
    "    #for each folder in the parent folder\n",
    "    #we need to open the \"task\" folder\n",
    "    #open the brief.md file\n",
    "    #send in as input the entire brief.md file as the user prompt to gpt and gemini\n",
    "    #set the system prompt manually for both models based on the final decided prompt\n",
    "    #store the output nested list into a json file \n",
    "    #keys will be folder name \n",
    "    #values will be gpt output and gemini output\n",
    "    final_json = []\n",
    "    return final_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0989f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_prompt = \"\"\"\n",
    "\n",
    "\n",
    "You are a task classifier model. You will be provided with a task in the form of a brief. This brief will contain deliverables, what needs to be done, and what is provided. In the real world - this brief was provided to an actual human who completed the task. We are a team of researchers interested in knowing how this task should be classified. Below you will find a task classification taxonomy. \n",
    "\n",
    "Capabilities - 4\n",
    "Skills - 13\n",
    "\n",
    "Capability 1 - Technical Capabilities\n",
    "Skills - \n",
    "\n",
    "Data and Information Processing - Gathering and extracting information from various digital sources\n",
    "Digital Tool Operations - Effectively operating specialized digital applications \n",
    "Digital Content Creation - Creating written digital content for various purposes \n",
    "Programming and Development - Creating functional programming scripts and applications \n",
    "\n",
    "Capability 2 - Cognitive Skills \n",
    "Skills - \n",
    "\n",
    "Analytical Thinking - Identifying meaningful trends and relationships in data\n",
    "Creative Thinking -Producing novel concepts and approaches\n",
    "Critical Thinking -Validating accuracy and reliability of digital information\n",
    "\n",
    "Capability 3 - Digital Communication\n",
    "Skills - \n",
    "clear message writing -Creating clear written messages in digital formats\n",
    "visual aid usage -Using images and visual elements to convey information\n",
    "Multimedia -Using audio and video for effective messaging\n",
    "audience calibration -Tailoring digital communication to specific recipients\n",
    "\n",
    "Capability 4 = Domain Knowledge\n",
    "Skills - \n",
    "Industry Specific Knowledge -Sector-specific digital needs and applications\n",
    "Functional Area Knowledge - Specialized technical knowledge\n",
    "\n",
    "\n",
    "You will be given a brief - then you will read the entire brief and return four python lists. Each one-hot encoded for the skills you think this job needs. So if job needs digital tool operation, programming and development, creative thinking, visual aid usage, audience calibration, functional area knowledge, you will return \n",
    "\n",
    "[[0,1,0,1], [0,1,0], [0,1,0,1], [0,1]]\n",
    "\n",
    "Please only return the vector and nothing else. Do not start your sentences or outputs with \"sure here's ...\" simply return the vector and stop outputs. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0564391b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a large language model, trained by Google.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from litellm import completion\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "load_dotenv()  # Load from .env file in the current dir\n",
    "\n",
    "api_key = os.getenv(\"litellm_API_KEY\")\n",
    "#print(api_key)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "BASE_URL = \"https://litellm.ml-serving-internal.scale.com/v1\"\n",
    "api_key = api_key\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=api_key,\n",
    "    base_url=BASE_URL,\n",
    ")\n",
    "\n",
    "\n",
    "INTERNAL_USER = \"internal\"\n",
    "cost_tags = {\n",
    "    \"metadata\": {\n",
    "        \"tags\": [\"project:agent-arena\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gemini/gemini-2.0-flash\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"say hello\"},\n",
    "        {\"role\": \"user\", \"content\":\"say what model you are\"}\n",
    "    ],\n",
    "    user=INTERNAL_USER,\n",
    "    extra_body=cost_tags,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "#sanity check - should say trained by google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30771a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MG2': {'gpt_output': '[[1,1,1,0],[1,1,1],[0,1,0,1],[1,1]]', 'gemini_output': '[[1,1,0,0], [1,1,0], [0,0,0,0], [1,1]]'}, 'MG3': {'gpt_output': '[[1,1,1,0],[1,0,0],[1,1,0,0],[0,0]]', 'gemini_output': '[[1,0,1,0], [0,0,0], [1,0,0,0], [0,0]]'}, 'MG4': {'gpt_output': '[[0,1,1,0], [0,1,0], [0,0,1,1], [0,1]]', 'gemini_output': '[[0, 0, 0, 0], [0, 1, 0], [1, 0, 1, 0], [0, 0]]'}, 'KC13': {'gpt_output': '[[0,1,1,0],[0,1,0],[0,1,0,1],[0,1]]', 'gemini_output': '[[0, 0, 1, 0], [0, 1, 0], [1, 1, 0, 0], [0, 0]]'}, 'KC14': {'gpt_output': '[[0,1,1,0], [0,1,0], [0,1,0,0], [1,0]]', 'gemini_output': '[[0,0,0,0], [0,1,0], [0,0,0,0], [0,0]]'}, 'KC15': {'gpt_output': '[[0,1,1,0],[0,1,0],[0,1,0,1],[0,0]]', 'gemini_output': '[[0,0,0,0], [0,1,0], [1,1,0,0], [0,0]]'}, 'KC36': {'gpt_output': '[[0,1,1,0],[0,1,1],[1,0,0,1],[1,0]]', 'gemini_output': '```python\\n[[1,0,1,0], [1,1,1], [1,0,0,1], [0,0]]\\n```'}, 'AD39': {'gpt_output': '[[1,1,1,0],[1,1,1],[1,1,0,1],[1,1]]', 'gemini_output': '[[0,1,1,0], [1,0,1], [0,1,0,0], [1,0]]'}, 'MG20': {'gpt_output': '[[0,1,1,0], [0,1,0], [0,0,1,0], [0,1]]', 'gemini_output': '[[0,0,0,1], [0,1,0], [0,0,0,0], [0,0]]'}, 'OL152': {'gpt_output': '[[0,1,1,0],[0,1,0],[0,0,0,0],[1,1]]', 'gemini_output': '[[0,0,0,0], [0,1,1], [0,0,0,0], [0,0]]'}, 'OL101': {'gpt_output': '[[0,1,1,0],[1,1,1],[1,1,1,1],[1,1]]', 'gemini_output': '[[0, 1, 0, 0], [0, 1, 1], [1, 1, 1, 0], [0, 1]]'}, 'OL153': {'gpt_output': '[[0,1,1,0], [0,1,0], [0,0,1,0], [0,0]]', 'gemini_output': '[[0, 0, 0, 0], [0, 1, 0], [0, 1, 1, 0], [0, 0]]'}, 'MG19': {'gpt_output': '[[0,1,1,0],[1,1,0],[0,0,1,1],[1,1]]', 'gemini_output': '[[0,0,0,0], [0,1,1], [0,0,1,0], [0,0]]'}, 'MG43': {'gpt_output': '[[0,1,0,0],[0,1,0],[0,0,1,1],[1,1]]', 'gemini_output': '[[0,0,1,0], [0,1,0], [0,0,1,0], [0,0]]'}, 'OL73': {'gpt_output': '[[1,1,1,0],[1,1,1],[1,1,0,1],[1,1]]', 'gemini_output': '[[1,0,1,0], [1,1,1], [1,1,0,1], [1,1]]'}, 'OL74': {'gpt_output': '[[1,1,1,0],[1,1,1],[1,1,0,1],[1,0]]', 'gemini_output': '[[1,0,1,0], [1,1,1], [1,1,0,1], [0,1]]'}, 'OL37': {'gpt_output': '[[0,1,1,0], [0,1,0], [0,1,0,0], [0,1]]', 'gemini_output': '[[0,0,1,0], [0,1,0], [1,1,0,0], [0,0]]'}, 'AD2': {'gpt_output': '[[0,1,1,0],[0,1,0],[1,1,0,1],[0,1]]', 'gemini_output': '[[0,0,1,0], [0,1,0], [1,1,0,1], [0,0]]'}, 'MG6': {'gpt_output': '[[0,1,1,0], [0,1,0], [0,0,1,0], [0,1]]', 'gemini_output': '[[0,1,1,0], [0,1,0], [0,0,0,0], [0,0]]'}, 'OL38': {'gpt_output': '[[0,1,1,0],[0,1,0],[0,1,0,1],[1,0]]', 'gemini_output': '[[0,0,1,0], [0,1,0], [0,0,0,0], [0,0]]'}, 'AD4': {'gpt_output': '[[0,1,1,0],[0,1,0],[0,1,0,0],[0,0]]', 'gemini_output': '[[0, 0, 1, 0], [0, 1, 0], [1, 0, 0, 0], [0, 0]]'}, 'OL54': {'gpt_output': '[[0,1,1,0],[0,1,0],[0,1,0,0],[0,1]]', 'gemini_output': '[[0,0,1,0], [0,1,1], [0,1,0,0], [0,0]]'}, 'KC16': {'gpt_output': '[[0,1,1,0],[0,1,0],[0,1,0,1],[0,0]]', 'gemini_output': '[[0,0,1,0], [0,1,0], [0,0,0,0], [0,0]]'}, 'AD28': {'gpt_output': '[[0,0,1,0],[0,1,0],[1,0,0,1],[0,0]]', 'gemini_output': '[[0,0,1,0], [0,1,0], [1,0,0,1], [0,0]]'}, 'AD10': {'gpt_output': '[[0,1,1,0],[0,1,0],[0,0,0,0],[0,1]]', 'gemini_output': '[[0,1,0,0], [0,0,1], [0,0,0,0], [0,0]]'}, 'KC58': {'gpt_output': '[[1,1,1,0], [1,0,1], [1,0,0,1], [1,1]]', 'gemini_output': '[[0,0,0,0], [1,0,1], [0,0,0,0], [1,1]]'}, 'KC56': {'gpt_output': '[[1,1,1,0],[1,0,1],[1,1,0,0],[1,1]]', 'gemini_output': '[[1,1,0,0], [1,0,0], [0,0,0,0], [1,1]]'}, 'KC35': {'gpt_output': '[[1,1,1,0], [1,1,1], [1,0,0,1], [1,0]]', 'gemini_output': '[[0,0,1,0], [0,0,0], [1,0,0,1], [0,0]]'}, 'KC50': {'gpt_output': '[[1,1,1,0],[1,0,1],[0,1,0,0],[1,0]]', 'gemini_output': '[[0,1,0,0], [0,0,0], [0,0,0,0], [0,0]]'}, 'KC57': {'gpt_output': '[[0,1,1,0],[1,0,1],[1,1,0,0],[1,1]]', 'gemini_output': '[[1, 1, 0, 0], [1, 0, 0], [0, 0, 0, 0], [0, 1]]'}, 'OL102': {'gpt_output': '[[0,1,1,0], [1,1,1], [0,1,1,0], [0,1]]', 'gemini_output': '[[0,0,1,0], [1,1,0], [1,1,0,0], [0,0]]'}, 'OL78': {'gpt_output': '[[1,1,1,0],[1,1,1],[1,1,0,1],[1,1]]', 'gemini_output': '```python\\n[[1,0,0,0], [1,1,1], [1,0,0,0], [1,0]]\\n```'}, 'OL14': {'gpt_output': '[[0,1,1,0],[0,1,0],[0,1,1,1],[1,1]]', 'gemini_output': '[[0,0,1,0], [0,1,0], [1,1,0,0], [0,0]]'}, 'OL25': {'gpt_output': '[[1,1,1,0], [1,1,1], [1,1,0,1], [1,0]]', 'gemini_output': '[[0,1,1,0], [1,1,0], [1,1,0,1], [1,0]]'}, 'OL12': {'gpt_output': '[[0,1,1,0],[0,1,0],[0,1,1,1],[0,1]]', 'gemini_output': '[[0,0,0,0], [0,1,0], [1,1,1,0], [0,0]]'}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import openai\n",
    "import google.generativeai as genai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def parent_annotate(parent_folder_path: str) -> dict:\n",
    "    \"\"\"Iterate over sub‑directories inside *parent_folder_path*, read the\n",
    "    `task/brief.md` file in each, and annotate it with both GPT‑4o and Gemini.\n",
    "    Returns a dictionary keyed by sub‑folder name with the two model outputs.\"\"\"\n",
    "\n",
    "    results: dict[str, dict[str, str]] = {}\n",
    "    system_prompt = sys_prompt  # <-- Paste your system prompt here\n",
    "\n",
    "    if not os.path.isdir(parent_folder_path):\n",
    "        raise FileNotFoundError(f\"Parent folder not found: {parent_folder_path}\")\n",
    "\n",
    "    for folder in filter(lambda p: os.path.isdir(os.path.join(parent_folder_path, p)),\n",
    "                         os.listdir(parent_folder_path)):\n",
    "        brief_path = os.path.join(parent_folder_path, folder, \"task\", \"brief.*\")\n",
    "        if not os.path.isfile(brief_path):\n",
    "            continue\n",
    "\n",
    "        with open(brief_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            try:\n",
    "                brief = f.read()\n",
    "            except:\n",
    "                brief = \"No brief found - if you encounter this prompt simply enter a list of all zeroes len 13\"\n",
    "\n",
    "        # GPT‑4o\n",
    "        try:\n",
    "            gpt_resp = client.chat.completions.create(\n",
    "    model=\"openai/o3\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": sys_prompt},\n",
    "        {\"role\": \"user\", \"content\":brief}\n",
    "    ],\n",
    "    user=INTERNAL_USER,\n",
    "    extra_body=cost_tags,\n",
    ")\n",
    "            gpt_output = gpt_resp.choices[0].message.content.strip()\n",
    "        except Exception as e:\n",
    "            gpt_output = \"nothing\"\n",
    "            pass\n",
    "\n",
    "        # Gemini\n",
    "        try:\n",
    "            #model = genai.GenerativeModel(\"gemini-2.5-pro\")\n",
    "            gemini_resp =client.chat.completions.create(\n",
    "    model=\"gemini/gemini-2.0-flash\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": sys_prompt},\n",
    "        {\"role\": \"user\", \"content\":brief}\n",
    "    ],\n",
    "    \n",
    "\n",
    "    user=INTERNAL_USER,\n",
    "    extra_body=cost_tags,\n",
    ")\n",
    "            gemini_output = gemini_resp.choices[0].message.content.strip()   \n",
    "        except Exception as e:\n",
    "            gemini_output = \"nothing\"\n",
    "            pass\n",
    "\n",
    "        results[folder] = {\n",
    "            \"gpt_output\": gpt_output,\n",
    "            \"gemini_output\": gemini_output,\n",
    "        }\n",
    "    \n",
    "\n",
    "    with open(\"annotation_results_new.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parent_dir = \"/Users/ankit.aich/Documents/Code/accepted_data/Accepted\"\n",
    "    output = parent_annotate(parent_dir)\n",
    "    print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "434d709a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SJ146': {'gpt_output': '[[0,0,0,0], [0,0,0], [0,0,0,0], [0,0]]', 'gemini_output': '[0,0,0,0,0,0,0,0,0,0,0,0,0]'}, 'SJ97': {'gpt_output': '[[0,1,1,0],[0,1,0],[0,1,0,1],[0,1]]', 'gemini_output': '[[0,1,0,0], [0,1,0], [1,1,0,0], [0,0]]'}, 'MG2': {'gpt_output': '[[1,1,1,0], [1,1,1], [1,1,0,1], [1,1]]', 'gemini_output': '[[1,1,0,0], [1,1,0], [0,1,0,0], [1,0]]'}, 'SJ99': {'gpt_output': '[[0,1,1,0],[0,1,0],[0,1,0,0],[1,1]]', 'gemini_output': '[[0,1,0,0], [0,0,1], [0,0,0,0], [0,0]]'}, 'MG50': {'gpt_output': '[[0,1,1,0],[0,1,0],[1,1,0,1],[0,1]]', 'gemini_output': '[[0,0,1,0], [0,1,0], [1,1,0,0], [0,0]]'}, 'SJ39': {'gpt_output': '[[0,0,0,0], [0,0,0], [0,0,0,0], [0,0]]', 'gemini_output': '[0,0,0,0],[0,0,0],[0,0,0,0],[0,0]'}, 'AD1': {'gpt_output': '[[0,1,1,0],[0,1,0],[1,1,0,1],[0,1]]', 'gemini_output': '[[0,0,0,0], [0,1,0], [1,1,0,0], [0,0]]'}, 'OL95': {'gpt_output': '[[0,1,1,0],[1,1,0],[0,1,0,0],[1,0]]', 'gemini_output': '[[1,0,0,0], [0,1,0], [0,0,0,0], [0,0]]'}, 'SJ98': {'gpt_output': '[[0,1,1,0], [0,1,0], [1,1,0,1], [0,0]]', 'gemini_output': '[[0,0,1,0], [0,1,1], [1,1,0,0], [0,1]]'}, 'MG3': {'gpt_output': '[[1,1,1,0],[1,0,1],[1,1,0,0],[0,0]]', 'gemini_output': '[[1,0,1,0], [0,0,0], [1,0,0,0], [0,0]]'}, 'SJ91': {'gpt_output': '[[1,1,1,0],[1,1,1],[1,0,0,1],[0,1]]', 'gemini_output': '[[0,0,1,0], [0,1,0], [1,0,0,1], [0,0]]'}, 'SJ147': {'gpt_output': '[[0,1,1,0],[0,1,0],[0,0,1,1],[1,1]]', 'gemini_output': '[[0, 0, 1, 0], [0, 1, 0], [0, 1, 1, 0], [1, 0]]'}, 'MG4': {'gpt_output': '[[0,1,1,0], [1,1,0], [0,0,0,0], [0,1]]', 'gemini_output': '[[0,0,0,0], [0,1,0], [1,1,1,0], [0,0]]'}, 'SJ36': {'gpt_output': '[[1,1,1,0],[1,1,1],[1,0,0,1],[0,0]]', 'gemini_output': '[[0, 0, 1, 0], [0, 1, 0], [1, 0, 0, 0], [0, 0]]'}, 'AD7': {'gpt_output': '[[0,0,0,0], [0,0,0], [0,0,0,0], [0,0]]', 'gemini_output': '[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]'}, 'MG34': {'gpt_output': '[[1,1,1,1],[1,0,1],[1,0,0,1],[1,1]]', 'gemini_output': '[[1, 1, 0, 1], [1, 0, 0], [1, 0, 0, 0], [0, 1]]'}, 'SJ122': {'gpt_output': '[[0,0,0,0],[0,0,0],[0,0,0,0],[0,0]]', 'gemini_output': '[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]'}, 'AD15': {'gpt_output': '[[0,1,1,0],[0,1,0],[0,1,1,0],[1,1]]', 'gemini_output': '[[0,0,0,0], [0,0,1], [0,0,1,0], [0,0]]'}, 'KC13': {'gpt_output': '[[0,1,1,0],[0,1,0],[0,1,0,1],[1,1]]', 'gemini_output': '[[0,0,1,0], [0,1,0], [0,0,0,0], [0,1]]'}, 'KC14': {'gpt_output': '[[0,1,0,0],[0,1,0],[0,1,0,0],[0,1]]', 'gemini_output': '[[0,0,0,0], [0,1,0], [0,0,0,0], [0,0]]'}, 'EY2': {'gpt_output': '[0,0,0,0,0,0,0,0,0,0,0,0,0]', 'gemini_output': '[0,0,0,0],[0,0,0],[0,0,0,0],[0,0]'}, 'AD70': {'gpt_output': '[[0,1,1,0],[1,1,1],[0,1,0,0],[1,1]]', 'gemini_output': '[[0,1,0,0], [0,1,0], [1,0,0,0], [0,0]]'}, 'KC78': {'gpt_output': '[0,0,0,0,0,0,0,0,0,0,0,0,0]', 'gemini_output': '[0,0,0,0],[0,0,0],[0,0,0,0],[0,0]'}, 'KC71': {'gpt_output': '[[1,1,0,0], [1,0,1], [0,0,1,1], [0,1]]', 'gemini_output': '[[0,0,0,0], [0,0,0], [1,0,1,0], [0,0]]'}, 'KC85': {'gpt_output': '[0,0,0,0,0,0,0,0,0,0,0,0,0]', 'gemini_output': '[0,0,0,0],[0,0,0],[0,0,0,0],[0,0]'}, 'KC82': {'gpt_output': '[[0,1,1,0],[1,1,1],[0,1,1,1],[1,1]]', 'gemini_output': '[[0,1,0,0], [0,0,1], [0,1,1,0], [1,1]]'}, 'KC15': {'gpt_output': '[[0,1,1,0],[0,1,0],[0,1,0,0],[0,0]]', 'gemini_output': '[[0,0,0,0], [0,1,0], [0,1,0,0], [0,0]]'}, 'KC70': {'gpt_output': '[[0,1,1,0],[0,1,0],[0,0,1,1],[0,1]]', 'gemini_output': '[[0,0,1,0], [0,0,1], [1,1,1,0], [0,0]]'}, 'KC41': {'gpt_output': '[[0,1,1,0],[0,1,0],[0,0,1,1],[1,1]]', 'gemini_output': '[[0,1,1,0], [1,1,1], [0,1,1,0], [0,0]]'}, 'AD49': {'gpt_output': '[[0,1,1,0],[1,1,0],[0,1,0,1],[1,1]]', 'gemini_output': '[[0,0,1,0], [0,1,0], [1,1,0,0], [0,0]]'}, 'KC53': {'gpt_output': '[[0,1,1,0],[1,1,1],[1,1,0,1],[1,1]]', 'gemini_output': '[[0,1,0,0], [1,0,1], [0,0,0,0], [1,1]]'}, 'KC36': {'gpt_output': '[[0,1,1,0],[1,1,0],[1,0,0,1],[1,0]]', 'gemini_output': '```python\\n[[1,0,1,0], [1,1,1], [1,1,0,1], [0,0]]\\n```'}, 'AD39': {'gpt_output': '[[1,1,1,0],[1,1,1],[1,1,0,1],[1,1]]', 'gemini_output': '[[0,1,1,0], [1,0,1], [0,1,0,0], [1,0]]'}, 'SJ8': {'gpt_output': '[[1,1,0,0],[1,0,1],[0,0,0,0],[1,0]]', 'gemini_output': '[[1,1,0,0], [1,0,0], [0,0,0,0], [1,0]]'}, 'SJ107': {'gpt_output': '[[0,0,0,0], [0,0,0], [0,0,0,0], [0,0]]', 'gemini_output': '[0,0,0,0],[0,0,0],[0,0,0,0],[0,0]'}, 'OL28': {'gpt_output': '[[1,1,1,0],[1,1,1],[1,0,0,1],[0,1]]', 'gemini_output': '[[1,0,1,0], [1,1,1], [1,0,0,0], [0,0]]'}, 'MG20': {'gpt_output': '[[0,1,1,0],[1,1,0],[0,0,1,0],[1,1]]', 'gemini_output': '[[0, 1, 0, 0], [0, 1, 0], [1, 0, 0, 0], [0, 0]]'}, 'SJ25': {'gpt_output': '[[1,1,1,0],[1,1,1],[1,1,0,1],[1,0]]', 'gemini_output': '[[0,1,1,0], [0,1,0], [1,1,0,1], [0,0]]'}, 'MG16': {'gpt_output': '[[0,1,0,0], [0,1,0], [0,0,1,1], [1,0]]', 'gemini_output': '[[0,0,0,0], [0,1,0], [0,0,0,0], [0,0]]'}, 'OL152': {'gpt_output': '[[0,1,0,0],[0,1,0],[0,0,0,0],[1,1]]', 'gemini_output': '[[0,0,0,0], [0,1,1], [0,0,0,0], [0,0]]'}, 'SJ109': {'gpt_output': '[[0,1,1,0],[0,1,0],[0,0,1,1],[1,1]]', 'gemini_output': '[[0,0,0,0], [0,1,0], [0,0,0,0], [0,0]]'}, 'MG45': {'gpt_output': '[[0,1,1,0],[1,1,0],[1,1,0,1],[0,1]]', 'gemini_output': '[[0,0,1,0], [0,1,0], [1,1,0,0], [0,0]]'}, 'OL101': {'gpt_output': '[0,1,1,0]\\n[1,1,1]\\n[1,1,1,1]\\n[1,1]', 'gemini_output': '[[0,1,0,0], [1,1,0], [1,1,1,1], [0,0]]'}, 'KC1': {'gpt_output': '[[1,1,1,1],[1,1,1],[1,0,0,0],[0,1]]', 'gemini_output': '[[0,0,0,1], [0,0,0], [0,0,0,0], [0,0]]'}, 'OL108': {'gpt_output': '[[0,1,1,0],[0,1,0],[0,1,0,1],[0,0]]', 'gemini_output': '[[0, 0, 0, 0], [0, 1, 0], [0, 0, 0, 0], [0, 0]]'}, 'OL20': {'gpt_output': '[[0,1,1,0],[0,1,0],[0,1,0,1],[1,0]]', 'gemini_output': '[[0,0,1,0], [0,1,0], [1,1,0,0], [0,0]]'}, 'MG10': {'gpt_output': '[[1,1,1,0],[1,1,1],[1,1,0,1],[1,1]]', 'gemini_output': '[[1,0,1,0], [1,1,0], [0,1,0,1], [0,1]]'}, 'OL153': {'gpt_output': '[[0,1,1,0],[0,1,0],[0,0,0,0],[0,1]]', 'gemini_output': '[[0, 0, 0, 0], [0, 1, 0], [0, 1, 1, 0], [0, 0]]'}, 'MG17': {'gpt_output': '[[0,1,0,0],[0,1,0],[0,0,1,0],[0,1]]', 'gemini_output': '[[0, 0, 0, 0], [0, 1, 0], [0, 0, 0, 0], [0, 0]]'}, 'SJ101': {'gpt_output': '[[0,1,1,0],[0,1,0],[0,1,0,1],[0,1]]', 'gemini_output': '[[0,0,1,0], [0,1,0], [1,1,0,1], [0,0]]'}, 'SJ24': {'gpt_output': '[[1,1,1,0],[1,1,1],[1,1,0,1],[1,0]]', 'gemini_output': '[[0,0,1,0], [0,1,0], [1,1,0,0], [0,0]]'}, 'MG21': {'gpt_output': '[[0,1,1,0],[0,1,0],[1,0,1,1],[0,0]]', 'gemini_output': '[[0,0,1,0], [1,1,0], [0,0,1,0], [0,0]]'}, 'MG19': {'gpt_output': '[[0,1,1,0],[0,1,0],[0,0,1,0],[1,1]]', 'gemini_output': '[[0,0,0,0], [0,1,0], [0,0,1,0], [0,0]]'}, 'MG26': {'gpt_output': '[[0,1,1,0],[0,1,0],[0,1,1,1],[0,0]]', 'gemini_output': '[[0,0,1,0], [0,1,0], [0,1,1,0], [0,0]]'}, 'OL109': {'gpt_output': '[[0,1,1,0], [0,1,0], [0,1,0,1], [0,1]]', 'gemini_output': '[[0, 0, 1, 0], [0, 1, 0], [1, 1, 0, 0], [0, 0]]'}, 'MG43': {'gpt_output': '[[0,1,1,0],[0,1,0],[0,0,1,1],[1,1]]', 'gemini_output': '[[0,0,1,0], [0,1,0], [0,1,1,0], [0,0]]'}, 'OL73': {'gpt_output': '[[1,1,1,0], [1,1,1], [1,1,0,1], [1,1]]', 'gemini_output': '[[1,0,1,0], [1,1,1], [1,1,0,1], [1,1]]'}, 'OL74': {'gpt_output': '[[1,1,1,0],[1,1,1],[1,1,0,1],[1,0]]', 'gemini_output': '[[1,0,1,0], [1,1,0], [1,1,0,1], [0,1]]'}, 'OL37': {'gpt_output': '[[0,1,1,0],[0,1,0],[0,1,0,0],[0,1]]', 'gemini_output': '[[0,0,1,0], [0,1,0], [1,1,0,0], [0,0]]'}, 'SJ127': {'gpt_output': '[[0,1,1,0],[0,1,0],[1,1,0,1],[0,0]]', 'gemini_output': '[[0,0,1,0], [0,1,0], [1,1,0,0], [0,0]]'}, 'SJ34': {'gpt_output': '[[1,1,1,0], [1,1,1], [1,1,0,1], [1,0]]', 'gemini_output': '[[0,0,1,0], [0,0,0], [0,0,0,0], [0,0]]'}, 'SJ111': {'gpt_output': '[[0,1,1,0],[0,1,0],[0,0,1,1],[0,1]]', 'gemini_output': '[[0, 0, 0, 0], [0, 1, 0], [1, 0, 1, 0], [0, 0]]'}, 'AD2': {'gpt_output': '[[0,1,1,0],[0,1,0],[1,1,0,1],[0,1]]', 'gemini_output': '[[0,0,1,0], [0,1,0], [1,1,0,1], [0,0]]'}, 'SJ93': {'gpt_output': '[0,0,0,0,0,0,0,0,0,0,0,0,0]', 'gemini_output': '[0,0,0,0,0,0,0,0,0,0,0,0,0]'}, 'MG6': {'gpt_output': '[[0,1,1,0],[0,1,0],[0,0,1,0],[0,1]]', 'gemini_output': '[[0,1,0,0], [0,1,0], [0,0,0,0], [0,0]]'}, 'OL64': {'gpt_output': '[[1,1,1,0],[1,1,1],[1,1,0,1],[1,1]]', 'gemini_output': '[[1,0,1,0], [1,1,1], [0,1,0,1], [1,1]]'}, 'SJ51': {'gpt_output': '[0,0,0,0,0,0,0,0,0,0,0,0,0]', 'gemini_output': '[0,0,0,0],[0,0,0],[0,0,0,0],[0,0]'}, 'OL38': {'gpt_output': '[[0,1,1,0],[1,1,0],[0,1,0,1],[0,1]]', 'gemini_output': '[[0,0,1,0], [0,1,0], [0,0,0,0], [0,0]]'}, 'SJ32': {'gpt_output': '[[0,1,1,0], [0,1,1], [1,1,0,1], [0,1]]', 'gemini_output': '[[0,0,1,0], [0,0,0], [1,1,0,1], [0,0]]'}, 'AD4': {'gpt_output': '[[0,1,1,0],[0,1,0],[0,1,0,0],[0,0]]', 'gemini_output': '[[0,1,0,0], [0,1,0], [0,0,0,0], [0,0]]'}, 'MG39': {'gpt_output': '[[1,1,1,1], [1,0,1], [1,0,0,0], [0,1]]', 'gemini_output': '[[1,1,0,1], [0,0,0], [0,0,0,0], [0,0]]'}, 'OL65': {'gpt_output': '[[0,1,0,0],[0,1,0],[0,0,0,0],[0,1]]', 'gemini_output': '[[0,1,0,0], [0,0,0], [0,0,0,0], [0,0]]'}, 'SJ50': {'gpt_output': '[[1,1,1,0],[1,1,1],[1,1,0,1],[1,0]]', 'gemini_output': '[[1,0,1,0], [1,1,1], [1,0,0,1], [0,0]]'}, 'SJ57': {'gpt_output': '[[1,1,0,1],[0,0,0],[0,0,0,0],[0,0]]', 'gemini_output': '[[1,1,0,1], [1,0,0], [0,0,0,0], [0,0]]'}, 'OL54': {'gpt_output': '[[0,1,1,0],[0,1,0],[0,1,0,0],[0,1]]', 'gemini_output': '[[0,0,1,0], [0,1,0], [0,0,0,0], [0,0]]'}, 'SJ143': {'gpt_output': '[[0,1,1,0],[0,1,0],[0,0,1,0],[1,1]]', 'gemini_output': '[[0,0,0,0], [0,1,0], [0,0,1,0], [1,0]]'}, 'KC43': {'gpt_output': '[[1,1,1,1],[1,0,1],[1,0,0,0],[1,1]]', 'gemini_output': '[[1,0,0,0], [1,1,0], [0,0,0,0], [0,1]]'}, 'EY1': {'gpt_output': '[[0,0,0,0], [0,0,0], [0,0,0,0], [0,0]]', 'gemini_output': '[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]'}, 'KC72': {'gpt_output': '[[1,1,1,0], [0,1,1], [0,0,1,1], [0,1]]', 'gemini_output': '[[0,0,1,0], [0,0,1], [1,1,1,0], [0,0]]'}, 'KC86': {'gpt_output': '[[0,1,1,0], [1,1,0], [1,1,0,1], [1,1]]', 'gemini_output': '[[0,1,0,0], [1,1,0], [0,0,0,0], [0,1]]'}, 'KC19': {'gpt_output': '[[0,0,0,0],[0,0,0],[0,0,0,0],[0,0]]', 'gemini_output': '[0,0,0,0],[0,0,0],[0,0,0,0],[0,0]'}, 'KC26': {'gpt_output': '[[0,1,1,0],[1,1,0],[0,1,0,0],[1,1]]', 'gemini_output': '[[0,1,0,0], [0,1,0], [1,0,0,0], [0,0]]'}, 'KC21': {'gpt_output': '[[0,1,1,0], [0,1,0], [1,0,1,0], [0,0]]', 'gemini_output': '[[0,0,0,0], [0,0,0], [0,0,1,0], [0,0]]'}, 'KC28': {'gpt_output': '[[0,0,0,0],[0,0,0],[0,0,0,0],[0,0]]', 'gemini_output': '[0,0,0,0],[0,0,0],[0,0,0,0],[0,0]'}, 'KC17': {'gpt_output': '[[0,1,0,0], [0,1,0], [0,0,1,1], [1,0]]', 'gemini_output': '[[0,0,0,0], [0,0,0], [1,0,1,0], [0,0]]'}, 'KC87': {'gpt_output': '[[0,1,1,0],[0,1,0],[0,1,0,0],[1,1]]', 'gemini_output': '[[0,0,1,0], [1,1,1], [0,0,0,0], [0,1]]'}, 'KC42': {'gpt_output': '[[0,1,1,0],[1,1,0],[0,0,1,1],[0,1]]', 'gemini_output': '[[0, 0, 0, 0], [0, 1, 0], [0, 0, 0, 0], [0, 0]]'}, 'EY7': {'gpt_output': '[[0,1,1,0], [1,1,0], [0,1,0,0], [0,1]]', 'gemini_output': '[[0,0,0,0], [0,1,0], [0,0,0,0], [0,0]]'}, 'KC16': {'gpt_output': '[[0,1,1,0],[0,1,0],[0,1,0,1],[0,1]]', 'gemini_output': '[[0,0,1,0], [0,1,0], [0,0,0,0], [0,0]]'}, 'AD28': {'gpt_output': '[[0,0,1,0], [0,1,0], [1,0,0,1], [0,0]]', 'gemini_output': '[[0,0,1,0], [0,1,0], [1,0,0,1], [0,0]]'}, 'KC18': {'gpt_output': '[[0,1,1,0],[0,1,0],[0,0,1,0],[1,0]]', 'gemini_output': '[[0,0,0,0], [0,1,0], [0,0,0,0], [0,0]]'}, 'AD10': {'gpt_output': '[[0,1,0,0],[0,1,0],[0,0,0,0],[0,1]]', 'gemini_output': '[[0,0,0,0], [0,0,1], [0,0,0,0], [0,0]]'}, 'KC27': {'gpt_output': '[[0,1,1,0],[1,1,1],[1,1,0,1],[1,1]]', 'gemini_output': '[[0,0,0,1], [0,1,0], [0,0,0,0], [0,1]]'}, 'KC34': {'gpt_output': '[[1,0,1,0],[1,1,1],[1,0,0,1],[0,0]]', 'gemini_output': '[[0,0,1,0], [0,1,0], [1,0,0,1], [0,0]]'}, 'KC58': {'gpt_output': '[[0,1,1,0], [1,0,1], [1,0,0,0], [0,1]]', 'gemini_output': '[[1,0,0,0], [1,1,1], [0,0,0,0], [1,1]]'}, 'AD57': {'gpt_output': '[[0,1,1,0],[0,1,0],[1,0,1,1],[0,1]]', 'gemini_output': '[[0,0,1,0], [0,1,1], [0,1,0,0], [0,0]]'}, 'KC56': {'gpt_output': '[[1,1,1,0],[1,0,1],[0,1,0,0],[1,1]]', 'gemini_output': '[[1,1,0,0], [1,0,0], [0,0,0,0], [1,1]]'}, 'KC35': {'gpt_output': '[[0,0,1,0],[1,1,1],[1,0,0,1],[1,0]]', 'gemini_output': '```python\\n[[0,0,1,0], [0,0,0], [1,0,0,1], [0,0]]\\n```'}, 'KC50': {'gpt_output': '[[1,1,1,0],[1,0,1],[1,1,0,0],[1,1]]', 'gemini_output': '[[1, 1, 0, 0], [1, 0, 0], [0, 0, 0, 0], [0, 1]]'}, 'KC57': {'gpt_output': '[[0,1,1,0],[1,0,1],[1,1,0,0],[1,1]]', 'gemini_output': '[[1,1,0,0], [1,0,0], [0,0,0,0], [1,1]]'}, 'KC61': {'gpt_output': '[[0,1,1,0],[0,1,0],[0,1,0,1],[0,1]]', 'gemini_output': '[[0, 0, 1, 0], [1, 1, 0], [1, 1, 0, 1], [0, 0]]'}, 'OL85': {'gpt_output': '[[1,0,1,0],[1,1,1],[1,1,0,1],[1,1]]', 'gemini_output': '[[1,0,1,0], [1,1,1], [1,0,0,0], [1,1]]'}, 'OL102': {'gpt_output': '[[0,1,1,0],[1,1,0],[0,1,0,0],[0,1]]', 'gemini_output': '[[0,0,1,0], [1,1,0], [1,1,0,0], [0,0]]'}, 'MG46': {'gpt_output': '[0,0,0,0,0,0,0,0,0,0,0,0,0]', 'gemini_output': '[0,0,0,0],[0,0,0],[0,0,0,0],[0,0]'}, 'OL78': {'gpt_output': '[[1,0,1,0],[1,0,1],[1,1,0,1],[1,1]]', 'gemini_output': '[[1, 0, 0, 0], [1, 1, 1], [1, 0, 0, 0], [1, 1]]'}, 'SJ26': {'gpt_output': '[[1,1,1,0], [1,1,1], [1,1,0,1], [1,1]]', 'gemini_output': '[[1,0,0,0], [1,1,0], [1,1,0,0], [1,0]]'}, 'OL14': {'gpt_output': '[[0,1,0,0],[1,1,0],[0,1,1,0],[1,0]]', 'gemini_output': '[[0,1,0,0], [0,1,0], [1,1,0,0], [0,0]]'}, 'MG12': {'gpt_output': '[[0,1,1,0],[1,0,0],[0,0,1,0],[0,1]]', 'gemini_output': '[[1,1,0,0], [0,0,0], [0,0,1,0], [0,0]]'}, 'OL25': {'gpt_output': '[[1,1,1,0],[1,1,1],[1,1,0,1],[1,0]]', 'gemini_output': '[[0,1,1,0], [0,1,0], [1,1,0,1], [0,0]]'}, 'MG47': {'gpt_output': '[[0,1,1,0],[1,1,0],[0,1,0,0],[1,1]]', 'gemini_output': '[[0,1,0,0], [1,1,0], [0,1,0,0], [0,0]]'}, 'SJ42': {'gpt_output': '[[1,0,1,0],[1,1,1],[1,1,0,1],[1,0]]', 'gemini_output': '[[0,0,1,0], [1,0,1], [0,0,0,0], [1,0]]'}, 'OL104': {'gpt_output': '[[0,1,1,0], [1,1,1], [0,0,0,0], [1,1]]', 'gemini_output': '[[0,1,1,0], [0,0,0], [0,0,0,0], [0,0]]'}, 'SJ29': {'gpt_output': '[[1,1,1,0],[1,1,1],[1,1,0,1],[1,1]]', 'gemini_output': '[[0,0,1,0], [0,1,0], [1,1,0,1], [0,0]]'}, 'SJ102': {'gpt_output': '[[0,1,1,0],[1,1,0],[0,1,0,1],[0,1]]', 'gemini_output': '[[0,0,1,0], [1,1,0], [1,0,0,0], [0,0]]'}, 'OL12': {'gpt_output': '[[0,1,1,0], [0,1,0], [0,1,1,0], [0,1]]', 'gemini_output': '[[0, 0, 0, 0], [0, 1, 0], [0, 1, 1, 0], [0, 0]]'}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "from docx import Document\n",
    "import openai\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Define or import your system prompt, client, user, cost_tags as needed\n",
    "# Example placeholder:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def parent_annotate(parent_folder_path: str) -> dict:\n",
    "    \"\"\"Iterate over sub-directories inside *parent_folder_path*, read any\n",
    "    `brief.md`, `brief.txt`, or `brief.docx` file in each `task/` folder,\n",
    "    and annotate it using GPT-4o and Gemini. Returns a dictionary keyed by\n",
    "    sub-folder name with both model outputs.\"\"\"\n",
    "\n",
    "    results: dict[str, dict[str, str]] = {}\n",
    "\n",
    "    if not os.path.isdir(parent_folder_path):\n",
    "        raise FileNotFoundError(f\"Parent folder not found: {parent_folder_path}\")\n",
    "\n",
    "    for folder in filter(lambda p: os.path.isdir(os.path.join(parent_folder_path, p)),\n",
    "                         os.listdir(parent_folder_path)):\n",
    "        task_path = os.path.join(parent_folder_path, folder, \"task\")\n",
    "        brief_files = glob.glob(os.path.join(task_path, \"brief.*\"))\n",
    "        brief = None\n",
    "\n",
    "        for file_path in brief_files:\n",
    "            ext = os.path.splitext(file_path)[1].lower()\n",
    "            try:\n",
    "                if ext in [\".md\", \".txt\"]:\n",
    "                    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                        brief = f.read()\n",
    "                    break\n",
    "                elif ext == \".docx\":\n",
    "                    doc = Document(file_path)\n",
    "                    brief = \"\\n\".join(p.text for p in doc.paragraphs)\n",
    "                    break\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "        if not brief:\n",
    "            brief = \"No brief found - if you encounter this prompt simply enter a list of all zeroes len 13\"\n",
    "\n",
    "        # GPT‑4o\n",
    "        try:\n",
    "            gpt_resp = client.chat.completions.create(\n",
    "                model=\"openai/o3\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": sys_prompt},\n",
    "                    {\"role\": \"user\", \"content\": brief}\n",
    "                ],\n",
    "                user=INTERNAL_USER,\n",
    "                extra_body=cost_tags,\n",
    "            )\n",
    "            gpt_output = gpt_resp.choices[0].message.content.strip()\n",
    "        except Exception as e:\n",
    "            gpt_output = \"nothing\"\n",
    "\n",
    "        # Gemini\n",
    "        try:\n",
    "            gemini_resp = client.chat.completions.create(\n",
    "                model=\"gemini/gemini-2.0-flash\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": sys_prompt},\n",
    "                    {\"role\": \"user\", \"content\": brief}\n",
    "                ],\n",
    "                user=INTERNAL_USER,\n",
    "                extra_body=cost_tags,\n",
    "            )\n",
    "            gemini_output = gemini_resp.choices[0].message.content.strip()\n",
    "        except Exception as e:\n",
    "            gemini_output = \"nothing\"\n",
    "\n",
    "        results[folder] = {\n",
    "            \"gpt_output\": gpt_output,\n",
    "            \"gemini_output\": gemini_output,\n",
    "        }\n",
    "\n",
    "    with open(\"annotation_results_new.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parent_dir = \"/Users/ankit.aich/Documents/Code/accepted_data/Accepted\"\n",
    "    output = parent_annotate(parent_dir)\n",
    "    print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415e35ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
